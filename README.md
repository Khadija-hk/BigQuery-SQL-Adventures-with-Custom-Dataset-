# BigQuery-SQL-Adventures-with-Custom-Dataset-
Welcome to GCP BigQuery repository. Get ready for a journey through a custom dataset with SQL query analysis and discover cool insights. Let us unlock the secrets of your data universe together! üöÄüîç

## Uploading Custom Dataset to BigQuery

1. **Prepare Your Dataset**: Make sure your dataset is formatted correctly and stored in a compatible file format such as CSV, JSON, or Avro. In this repository, I have used ‚Äògoogleplaystore‚Äô CSV file as an example.

2. **Create a BigQuery Dataset**: 
    - Go to the [BigQuery Console](https://console.cloud.google.com/bigquery).
    - In the navigation panel, click on your project name.
    - Click on the "Create dataset" button.
    - Enter a Dataset ID and choose appropriate options for Data location and Default table expiration.
    - Click "Create dataset" to create your dataset.

3. **Upload Your Dataset**:
    - Click on your newly created dataset in the navigation panel.
    - Click on the "Create table" button.
    - Choose the option to upload a file.
    - Select your file from your local machine.
    - Choose appropriate options for Schema and Table name.
    - Click "Create table" to upload your dataset.

## Executing Provided Queries

1. **Open Query Editor**:
    - In the navigation panel, click on your project name.
    - Click on your dataset.
    - Click on the "Query Table" button to open the Query Editor.

2. **Copy and Paste Queries**:
    - Open the ‚Äòqueries‚Äô file containing the queries provided.
    - Copy the SQL queries from the file.

3. **Execute Queries**:
    - Paste the queries into the Query Editor.
    - Click on the "Run" button to execute the queries.
    - Review the results in the query results pane.

4. **Explore and Analyze**:
    - Feel free to modify the queries or explore additional analyses using BigQuery's powerful SQL capabilities.

Enjoy your BigQuery adventure!
